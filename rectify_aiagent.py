# -*- coding: utf-8 -*-
"""Rectify_AIagent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bYqfZVpsFZCJ2CVYXvMRq17S_Ul6uZMc
"""

# Install lightweight libs
!pip install --quiet textblob matplotlib

# NLTK/TextBlob setup
import nltk
nltk.download('punkt', quiet=True)

# Imports and global config
import os, json, re, math, sys
from datetime import datetime, timedelta
from textblob import TextBlob
import matplotlib.pyplot as plt

# Persistent log file
LOG_PATH = "reflectify_logs.json"

# Safety / efficiency params
MAX_INPUT_CHARS = 4000    # truncate extremely long inputs
RAG_TOP_K = 3             # number of retrieved past reflections
RAG_TOKEN_WEIGHT = 0.7    # weighting for token-overlap scoring heuristics

def safe_load_logs(path=LOG_PATH):
    """Load logs safely; if missing or corrupt, return empty list and repair file."""
    if not os.path.exists(path):
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
    except Exception as e:
        print("Warning: could not read logs (corrupt?), starting fresh. Error:", e)
    # create fresh file
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump([], f)
    except Exception:
        pass
    return []

def safe_save_logs(logs, path=LOG_PATH):
    """Atomic write to avoid corruption."""
    tmp = path + ".tmp"
    try:
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(logs, f, indent=2, ensure_ascii=False)
        os.replace(tmp, path)
    except Exception as e:
        print("Error saving logs:", e)

def normalize_text(text):
    """Clean whitespace and truncate to MAX_INPUT_CHARS for speed."""
    if text is None:
        return ""
    s = str(text).strip()
    s = re.sub(r'\s+', ' ', s)
    if len(s) > MAX_INPUT_CHARS:
        s = s[:MAX_INPUT_CHARS] + " ... [truncated]"
    return s

def require_nonempty(text):
    t = normalize_text(text)
    return t if t else None

def tokenize_simple(text):
    """Simple tokenization: lowercase words, remove punctuation-like characters."""
    t = normalize_text(text).lower()
    # keep words only
    tokens = re.findall(r'\b\w+\b', t)
    return tokens

def analyze_sentiment(text):
    """Return mood_score (0..1), subjectivity, polarity (-1..1)."""
    t = normalize_text(text)
    if not t:
        return {"mood_score": 0.5, "subjectivity": 0.5, "polarity": 0.0}
    blob = TextBlob(t)
    polarity = blob.sentiment.polarity
    subj = blob.sentiment.subjectivity
    mood = round((polarity + 1) / 2, 3)
    return {"mood_score": mood, "subjectivity": round(subj,3), "polarity": round(polarity,3)}

def extract_activities(text, max_items=8):
    """Heuristic extraction: short activity phrases; priority to known action verbs."""
    t = normalize_text(text)
    if not t:
        return []
    parts = re.split(r'[.;\n]', t)
    activities = []
    keywords = r'\b(study|read|work|sleep|exercise|walk|run|meet|call|play|watch|code|practice|submit|revise|review|write|learn|attend|eat|cook|shop)\b'
    for p in parts:
        s = p.strip()
        if not s:
            continue
        if len(s.split()) <= 6:
            activities.append(s)
        elif re.search(keywords, s, flags=re.I):
            activities.append(s)
        if len(activities) >= max_items:
            break
    # trim and normalize
    return [a if len(a)<=140 else a[:137]+"..." for a in activities]

def reflection_agent(daily_text):
    """Produce reflection summary, suggestions, activities, and sentiment metrics."""
    t = normalize_text(daily_text)
    if not t:
        return {
            "summary": "No input provided.",
            "suggestions": ["Please write 1-3 sentences about your day."],
            "activities": [],
            "mood_score": 0.5,
            "subjectivity": 0.5,
            "polarity": 0.0
        }
    sent = analyze_sentiment(t)
    activities = extract_activities(t)
    # summary heuristics: first 1-2 sentences or fallback templated phrase
    sentences = re.split(r'(?<=[.?!])\s+', t)
    summary = sentences[0] if sentences else t
    if len(sentences) > 1:
        summary = sentences[0] + " " + (sentences[1] if len(sentences[1])<200 else sentences[1][:197]+"...")
    if len(summary) > 300:
        summary = summary[:297] + "..."
    # suggestions: rules combining keywords and mood
    suggestions = []
    if sent["mood_score"] < 0.45:
        suggestions.append("Include a short restorative activity (20-min walk or break) tomorrow.")
    if re.search(r'\b(study|exam|assignment|project|read|revise|practice|code)\b', t, flags=re.I):
        suggestions.append("Schedule a focused study block (45-60 min) with a short break.")
    if re.search(r'\b(social|friends|party|dinner|hangout)\b', t, flags=re.I):
        suggestions.append("Reflect on which social interactions were energizing vs draining.")
    if not suggestions:
        suggestions.append("Write a short priority list (top 3) for tomorrow to maintain focus.")
    # dedupe and limit
    seen = set(); uniq = []
    for s in suggestions:
        if s not in seen:
            uniq.append(s); seen.add(s)
        if len(uniq) >= 4:
            break
    return {
        "summary": summary,
        "suggestions": uniq,
        "activities": activities,
        "mood_score": sent["mood_score"],
        "subjectivity": sent["subjectivity"],
        "polarity": sent["polarity"]
    }

def rag_score_simple(query_tokens, doc_tokens):
    """
    Fast overlap-based score with token frequency weighting.
    Score scaled 0..1 (approx).
    """
    if not query_tokens or not doc_tokens:
        return 0.0
    # common tokens intersection with weighting by token counts
    qset = {}
    for t in query_tokens:
        qset[t] = qset.get(t,0) + 1
    dset = {}
    for t in doc_tokens:
        dset[t] = dset.get(t,0) + 1
    # compute weighted overlap
    overlap = 0.0
    for tok, qcount in qset.items():
        if tok in dset:
            overlap += min(qcount, dset[tok])
    # normalize by average length
    denom = (len(query_tokens) + len(doc_tokens)) / 2.0
    score = overlap / denom if denom > 0 else 0.0
    # boost by presence of important tokens (numbers, "exam", "deadline")
    boost_tokens = {"exam","deadline","assignment","due","interview","presentation","project","test","score"}
    boost = 0
    for b in boost_tokens:
        if b in qset and b in dset:
            boost += 0.2
    score = min(1.0, score * (1.0 - RAG_TOKEN_WEIGHT) + score * RAG_TOKEN_WEIGHT + boost)
    return round(float(score), 4)

def rag_retrieve_internal(query_text, logs, top_k=RAG_TOP_K):
    """
    Retrieve top-k past reflections from logs ranked by keyword overlap score.
    Returns list of (score, record) sorted descending.
    """
    qtokens = tokenize_simple(query_text)
    if not logs:
        return []
    scored = []
    for rec in logs:
        # build a lightweight doc text from summary + suggestions + activities
        doc_text_parts = []
        if isinstance(rec.get("reflection",{}).get("summary"), str):
            doc_text_parts.append(rec["reflection"]["summary"])
        doc_text_parts.extend(rec["reflection"].get("suggestions", []))
        doc_text_parts.extend(rec.get("planned_goals", []) and [g.get("goal","") for g in rec.get("planned_goals", [])] or [])
        doc_text = " ".join([str(x) for x in doc_text_parts])
        dtokens = tokenize_simple(doc_text)
        score = rag_score_simple(qtokens, dtokens)
        if score > 0:
            scored.append((score, rec))
    scored.sort(key=lambda x: -x[0])
    return scored[:top_k]

def planner_agent(reflection_out):
    """Convert suggestions into 1-4 concrete goals with type & priority."""
    if not reflection_out:
        return []
    goals = []
    for s in reflection_out.get("suggestions", []):
        s_low = s.lower()
        # classify
        if any(k in s_low for k in ["study","focus","task","project","assignment","revise","practice","read","code"]):
            g = {"goal": "Do one focused study block (45 min) with a planned break", "type":"productivity", "priority":2}
        elif any(k in s_low for k in ["walk","rest","sleep","restorative","exercise","break"]):
            g = {"goal": "Take a 20-min restorative walk or short rest", "type":"wellness", "priority":3}
        elif any(k in s_low for k in ["social","friends","reflect"]):
            g = {"goal": "Reflect on social energy after interactions (note feelings)", "type":"social", "priority":4}
        else:
            g = {"goal": s if len(s)<140 else s[:137]+"...", "type":"routine", "priority":5}
        goals.append(g)
        if len(goals) >= 4:
            break
    # ensure at least one productivity goal
    if not any(g["type"]=="productivity" for g in goals):
        goals.insert(0, {"goal": "Complete one prioritized task (30-60 min)", "type":"productivity", "priority":1})
    return goals

def executor_agent(today_text, logs):
    """
    Look up most recent planned_goals in logs and mark done/partial/missed based on heuristics.
    Returns statuses list.
    """
    if not logs:
        return []
    # find most recent with planned_goals
    last = None
    for rec in reversed(logs):
        if rec.get("planned_goals"):
            last = rec
            break
    if not last:
        return []
    statuses = []
    t = normalize_text(today_text).lower()
    for g in last.get("planned_goals", []):
        goal_text = g.get("goal","").lower()
        # check keywords overlap
        goal_tokens = set(tokenize_simple(goal_text))
        match_count = sum(1 for w in goal_tokens if w in t)
        # check for explicit done words
        done_words = {"done","completed","finished","did","worked","submitted","sent","uploaded"}
        if any(dw in t for dw in done_words) and match_count >= 1:
            status = "done"
        elif match_count >= max(1, min(3, len(goal_tokens)//2)):
            status = "partial"
        else:
            status = "missed"
        statuses.append({"goal": g.get("goal"), "status": status})
    return statuses

def evaluator_agent(logs, window_days=7):
    """Compute metrics: consistency, avg mood, goal completion rate, improvement."""
    if not logs:
        return {
            "goal_completion_rate": None,
            "consistency": 0.0,
            "avg_mood": None,
            "improvement_index": None,
            "notes": ["No logs present yet."]
        }
    cutoff = datetime.now() - timedelta(days=window_days)
    recent = [l for l in logs if datetime.strptime(l["date"], "%Y-%m-%d %H:%M:%S") >= cutoff]
    recent = recent if recent else logs[-window_days:]
    # consistency
    dates = set(datetime.strptime(l["date"], "%Y-%m-%d %H:%M:%S").date() for l in recent)
    consistency = round(len(dates) / float(window_days), 3)
    # goal completion
    comp_rates = []
    for l in recent:
        exec_stat = l.get("executor_statuses", [])
        if exec_stat:
            done = sum(1 for s in exec_stat if s.get("status")=="done")
            total = max(1, len(exec_stat))
            comp_rates.append(done/total)
    goal_completion_rate = round(sum(comp_rates)/len(comp_rates),3) if comp_rates else None
    # mood
    moods = [l.get("mood_score", 0.5) for l in recent]
    avg_mood = round(sum(moods)/len(moods),3) if moods else None
    improvement_index = None
    if len(moods) >= 2:
        improvement_index = round(moods[-1] - moods[0], 3)
    # notes
    notes = []
    if consistency < 0.3:
        notes.append("Low logging consistency; aim to log daily.")
    if goal_completion_rate is not None and goal_completion_rate < 0.4:
        notes.append("Goal completion rate is low; try smaller, measurable goals.")
    if improvement_index and improvement_index > 0:
        notes.append("Positive mood trend observed.")
    elif improvement_index and improvement_index < 0:
        notes.append("Mood trend is declining; reflect on causes.")
    return {
        "goal_completion_rate": goal_completion_rate,
        "consistency": consistency,
        "avg_mood": avg_mood,
        "improvement_index": improvement_index,
        "notes": notes
    }

def orchestrator_entry(daily_text):
    """
    Orchestrator runs: Reflection -> RAG -> Planner -> Executor -> Evaluator.
    Saves a record to logs and returns it.
    """
    logs = safe_load_logs()
    text = normalize_text(daily_text)
    if not text:
        print("Empty input; nothing recorded.")
        return None

    # 1) Reflection Agent
    reflection = reflection_agent(text)

    # 2) Internal RAG retrieval (context augmentation)
    retrieved = rag_retrieve_internal(text, logs, top_k=RAG_TOP_K)
    # Prepare augmentation: combine retrieved summaries for traceability
    rag_context = [{"score": s, "date": r["date"], "summary": r.get("reflection",{}).get("summary","")} for s,r in retrieved]

    # 3) Planner Agent (create next-day goals)
    planned_goals = planner_agent(reflection)

    # 4) Executor Agent (check previous day's goal completion)
    executor_statuses = executor_agent(text, logs)

    # Build record with agent message logs for explainability
    record = {
        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "raw_text": text,
        "reflection": reflection,
        "rag_retrieved": rag_context,
        "planned_goals": planned_goals,
        "executor_statuses": executor_statuses
    }

    # Append and save (first time)
    logs.append(record)
    safe_save_logs(logs)

    # 5) Evaluator Agent: compute metrics and attach to record
    logs = safe_load_logs()  # reload to get updated logs
    eval_report = evaluator_agent(logs)
    # attach evaluator summary to the latest record
    logs[-1]["evaluator_summary"] = eval_report
    safe_save_logs(logs)

    # Return the saved record (latest)
    return logs[-1]

def plot_mood_trend(path=LOG_PATH, last_n=14):
    logs = safe_load_logs(path)
    if not logs:
        print("No data to plot.")
        return
    logs_sorted = sorted(logs, key=lambda x: datetime.strptime(x["date"], "%Y-%m-%d %H:%M:%S"))
    data = logs_sorted[-last_n:]
    dates = [datetime.strptime(x["date"], "%Y-%m-%d %H:%M:%S").date() for x in data]
    moods = [x.get("mood_score", x.get("reflection",{}).get("mood_score", 0.5)) for x in data]
    plt.figure(figsize=(10,4))
    plt.plot(dates, moods, marker='o', linewidth=2)
    plt.ylim(-0.05,1.05)
    plt.axhline(0.5, color='gray', linestyle='--', linewidth=0.7)
    plt.title("Reflectify — Mood Trend (last {} entries)".format(len(dates)))
    plt.ylabel("Mood score (0..1)")
    plt.xlabel("Date")
    plt.grid(alpha=0.2)
    plt.show()

def pretty_print_record(record):
    if not record:
        print("No record to display.")
        return
    print("=== Reflectify Report ===")
    print("Date:", record.get("date"))
    print("\n-- Reflection Summary --")
    print(record.get("reflection",{}).get("summary",""))
    print("\n-- Suggestions --")
    for s in record.get("reflection",{}).get("suggestions",[]):
        print("-", s)
    print("\n-- Activities --")
    for a in record.get("reflection",{}).get("activities",[]):
        print("-", a)
    print("\n-- RAG Retrieved Context --")
    for r in record.get("rag_retrieved",[]):
        print(f"- [{r['date']}] score={r['score']}: {r['summary']}")
    print("\n-- Planned Goals --")
    for g in record.get("planned_goals",[]):
        print("-", g.get("goal"), f"({g.get('type')})")
    print("\n-- Executor Statuses (for previous goals) --")
    for es in record.get("executor_statuses",[]):
        print("-", es.get("goal"), "→", es.get("status"))
    print("\n-- Evaluator Summary --")
    ev = record.get("evaluator_summary", {})
    for k,v in ev.items():
        if k != "notes":
            print(f"{k}: {v}")
    print("Notes:", ev.get("notes", []))

def create_sample_logs(n_days=50):
    """Generate n_days of pseudo-realistic daily reflections."""
    base_texts = [
        "Had a productive day studying and exercising.",
        "Felt tired due to long classes and late-night project work.",
        "Enjoyed quality time with friends; relaxed and recharged.",
        "Faced difficulty focusing today; must plan breaks better.",
        "Completed assignments before deadline; satisfied and calm.",
        "Skipped gym; read a new article on AI and took notes.",
        "Worked on coding task; encountered bugs but fixed them.",
        "Went for an evening walk; cleared my mind and planned tomorrow.",
        "Studied chemistry for 3 hours; revision helped me feel confident.",
        "Had a stressful day managing multiple deadlines."
    ]

    logs = safe_load_logs()
    existing_texts = {entry.get("raw_text") for entry in logs}
    base_date = datetime.now() - timedelta(days=n_days)
    added = 0

    for i in range(n_days):
        s = base_texts[i % len(base_texts)] + f" (day {i+1})"
        if s in existing_texts:
            continue
        fake_date = (base_date + timedelta(days=i)).strftime("%Y-%m-%d %H:%M:%S")
        rec = orchestrator_entry(s)
        rec["date"] = fake_date
        logs.append(rec)
        added += 1

    safe_save_logs(logs)
    print(f"✅ {added} sample logs (spanning {n_days} days) created.")

# Run once
create_sample_logs(50)

print("Reflectify — daily log input. Enter 1-4 sentences describing your day.")
user_text = input("Your day: ").strip()
if not user_text:
    print("No input provided. Aborting.")
else:
    rec = orchestrator_entry(user_text)
    pretty_print_record(rec)
    print("\nSaved. Use the weekly summary cell to view trends and metrics.")

# Weekly summary (evaluator) and plotting
logs = safe_load_logs()
eval_report = evaluator_agent(logs, window_days=7)
print("Weekly evaluator summary:")
print(json.dumps(eval_report, indent=2, ensure_ascii=False))
print("\nPlotting mood trend (last 14 entries):")
plot_mood_trend()

